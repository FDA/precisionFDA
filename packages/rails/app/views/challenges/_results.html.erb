<div class="challenge-section">
  <div class="tab-content">
    <div role="tabpanel" class="tab-pane active">
      <div class="container container-padded">
        <div class="pfda-challenge-intro">
          <div class="lead-intro">
            The precisionFDA Hidden Treasures – Warm Up ran from July 19, 2017 to September 13, 2017. It provided participants a unique opportunity to investigate the accuracy of their pipelines by testing the ability to find <i>in silico</i> injected variants in FASTQ files from exome sequencing of reference cell lines. It was offered as a warm up ahead of potentially more difficult <i>in silico</i> challenge(s) to come. There were 86 valid entries from 30 participants to the challenge.
          </div>
          <div class="lead">
            This precisionFDA Hidden Treasures – Warm Up challenge results page displays the summarized results as two separate tables, with the opportunity to click on some of the features in each table and get more detailed information. As with previous challenges, due to novelties related to the truth data and the comparison methodology, these results offer a first glance at our understanding. We welcome the community to further explore these results and provide insight for the future.
            <br/>
            <br/>
          </div>
        </div>
        <div class="challenge-section">
          <div class="h2">Introductory Remarks</div>
          <p>
            At the start of this challenge, users were provided with a NA12878 whole exome sequencing FASTQ file that had been <i>in silico</i> modified with single nucleotide variants (SNVs) and insertion and deletion (InDel) variants (less than 40 bp) at approximate Variant Allele Frequencies (VAFs) ≥20%. <strong><%= link_to("This precisionFDA note", "https://precision.fda.gov/notes/330-precisionfda-hidden-treasures-warm-up") %></strong> summarizes certain precisionFDA artifacts related to the challenge, including a VCF with the injected variants, as well as the VCF evaluation app which was used by the system to automatically evaluate all entries. We invite the community to try the evaluation app and give us any feedback.
          </p>
          <br/>
          <div class="h2">Overview of Results</div>
          <p>
            Challenge participants ran the modified FASTQ file through their pipeline(s), and returned the resulting VCF file to precisionFDA for comparison to the known reference truth using a VCF evaluation app that we created. <strong>The first table below</strong> shows calls for 50 injected variants, including SNVs and InDels sorted separately by size (1-3 bp, 4-6 bp, 7-9 bp, 10-12 bp, and larger than 13 bp), for each entry in a separate row. Results shown for each entry also include whole exome recall, precision and F-score* for overall SNVs and overall InDels:
            <ul>
              <li>
                <strong>Recall</strong>, or sensitivity, reflects the percentage of variants in the NIST/GiaB benchmark set that were exactly called by the challenge participant pipeline in a submitted dataset.
              </li>
              <li>
                <strong>Precision</strong>, or positive predictive value, reflects the percentage of called variants which match exactly the NIST/GiaB benchmark set.
              </li>
              <li>
                <strong>F-score</strong> is the harmonic mean of recall and precision, and is sometimes used as a single combined metric for evaluating overall accuracy.
              </li>
            </ul>
            The entries are <strong>sorted alphabetically</strong> by the name of the submitter, since many submitters had multiple entries. Moreover, the Entry column contains a link to the precisionFDA job that resulted from the execution of the evaluation app on that entry. All jobs, and the resulting files as output by the evaluation app, have been made public on precisionFDA and are owned by the special user 'Challenge Robot'.
          </p>
          <p>
            Participants whose submissions correctly detected and called all 50 injected variants (regardless of the whole exome precision, recall and F-score for their pipeline/submission) are being recognized as <strong><i>Warm Up in silico Variant Catchers</i></strong> and are designated with the <%= recognition_badge("variantcatcher") %> icon in the table (45 entries earned that title).
          </p>
          <div class="text-muted small">
            <p>
              * The terminology currently used in this discussion (such as "precision" and "recall") is not necessarily harmonized with definitions used by ISO, CLSI, or FDA, but are terms commonly used by NGS software developers.
            </p>
          </div>
          <br/>
          <div class="table-responsive">
            <table id="table-results-overview" class="table table-condensed table-bordered table-nowrap table-sort table-hover table-challenge">
              <thead>
                <tr>
                  <td colspan="3"></td>
                  <td colspan="5">Injected indels</td>
                  <td colspan="2">Injected</td>
                  <td colspan="3">Whole-exome SNP</td>
                  <td colspan="3">Whole-exome indel</td>
                </tr>
                <tr>
                  <th class='sort-default' data-sort-method='string'>Submitter</th>
                  <th>Organization</th>
                  <th>Entry</th>
                  <th>1-3</th>
                  <th>4-6</th>
                  <th>7-9</th>
                  <th>10-12</th>
                  <th>13+</th>
                  <th rowspan="2">SNPS</th>
                  <th rowspan="2">Total</th>
                  <th>precision</th>
                  <th>recall</th>
                  <th>F-score</th>
                  <th>precision</th>
                  <th>recall</th>
                  <th>F-score</th>
                </tr>
              </thead>
              <tbody>
                <% submissions.each do |submission| %>
                  <tr>
                    <td data-sort="<%= submission.user.full_name %>">
                      <%= submission.user.full_name.titleize %>
                      <%= recognition_badge("variantcatcher") if submission.job.run_outputs["overall"] == 50 %>
                    </td>
                    <td data-sort="<%= submission.user.singular? ? "" : submission.user.org.name %>">
                      <%= submission.user.singular? ? "" : submission.user.org.name %>
                    </td>
                    <td data-sort="<%= submission.name %>">
                      <%= link_to(submission.name, job_path(submission.job)) %>
                    </td>
                    <td data-sort="<%= submission.job.run_outputs["indels_01_03"] %>">
                      <%= submission.job.run_outputs["indels_01_03"] %>
                    </td>
                    <td data-sort="<%= submission.job.run_outputs["indels_04_06"] %>">
                      <%= submission.job.run_outputs["indels_04_06"] %>
                    </td>
                    <td data-sort="<%= submission.job.run_outputs["indels_07_09"] %>">
                      <%= submission.job.run_outputs["indels_07_09"] %>
                    </td>
                    <td data-sort="<%= submission.job.run_outputs["indels_10_12"] %>">
                      <%= submission.job.run_outputs["indels_10_12"] %>
                    </td>
                    <td data-sort="<%= submission.job.run_outputs["indels_13_plus"] %>">
                      <%= submission.job.run_outputs["indels_13_plus"] %>
                    </td>
                    <td data-sort="<%= submission.job.run_outputs["snps"] %>">
                      <%= submission.job.run_outputs["snps"] %>
                    </td>
                    <td data-sort="<%= submission.job.run_outputs["overall"] %>">
                      <%= submission.job.run_outputs["overall"] %>
                    </td>
                    <td data-sort="<%= submission.job.run_outputs["exome_snp_precision"] %>">
                      <%= submission.job.run_outputs["exome_snp_precision"] %>
                    </td>
                    <td data-sort="<%= submission.job.run_outputs["exome_snp_recall"] %>">
                      <%= submission.job.run_outputs["exome_snp_recall"] %>
                    </td>
                    <td data-sort="<%= submission.job.run_outputs["exome_snp_fscore"] %>">
                      <%= submission.job.run_outputs["exome_snp_fscore"] %>
                    </td>
                    <td data-sort="<%= submission.job.run_outputs["exome_indel_precision"] %>">
                      <%= submission.job.run_outputs["exome_indel_precision"] %>
                    </td>
                    <td data-sort="<%= submission.job.run_outputs["exome_indel_recall"] %>">
                      <%= submission.job.run_outputs["exome_indel_recall"] %>
                    </td>
                    <td data-sort="<%= submission.job.run_outputs["exome_indel_fscore"] %>">
                      <%= submission.job.run_outputs["exome_indel_fscore"] %>
                    </td>
                  </tr>
                <% end %>
              </tbody>
            </table>
          </div>
          <br/>
          <p>
            <strong>The second table</strong> provides detailed variant detection information for each of the 50 injected variants from all qualified submissions. This table also specifies all injected variants with their expected VAF. In this table, VAF is displayed if the variant is present in submitted VCF for a specific entry and the VAF information was derived from the VCF file (i.e. VAF, AD/DP, or AB meta tag was available in the VCF file). For variants which were present in the VCF file, but failed to pass the filtering criteria (as defined by the filter meta tag), the variant is annotated as “filtered” with its associated VAF.

            Participant entries that supplied VAF data in accordance with the challenge instructions, and that detected all 50 variants reasonably close to the expected VAF values, are being recognized as <strong><i>Warm Up in silico VAF Spotters</i></strong>, indicated by the <%= recognition_badge("vafspotter") %> icon in the table below (37 entries earned this title). These recognitions are based on the information found in raw VCF data for each entry, regardless of whether the submitter called each of the variants as above 20%. This is due to various reasons, including quality filters set for the pipeline.
          </p>
          <br/>
          <% if csv && headers && keys && csv_names && csv_ids %>
            <div class="table-responsive">
              <table id="table-results-vaf" class="table table-condensed table-bordered table-nowrap table-sort table-hover table-challenge">
                <thead>
                  <tr>
                    <th class='sort-default' data-sort-method='string'>Entry</th>
                    <% (1..headers.first.length-1).each do |i| %>
                      <th>
                        Variant <%= headers[keys.index("VARID")][i] %>
                        <br/>
                        <hr/>
                        chr: <%= headers[keys.index("CHROM")][i] %>
                        <br/>
                        pos: <%= headers[keys.index("POS")][i] %>
                        <br/>
                        <%= headers[keys.index("REF")][i] %> <span class="fa fa-long-arrow-right"></span> <%= headers[keys.index("ALT")][i] %>
                        <br/>
                        true vaf: <%= '%.2f' % headers[keys.index("TRU VAF")][i] %>
                        <br/>
                        target vaf: <%= '%.2f' % headers[keys.index("TGT VAF")][i] %>
                      </th>
                    <% end %>
                  </tr>
                </thead>
                <tfoot>
                </tfoot>
                <tbody>
                  <% csv.each_with_index do |row, i| %>
                    <% job = vaf_results[i].try(:job) %>
                    <tr>
                      <td>
                        <%= job.nil? ? csv_names[i] : link_to(job.name, job_path(job)) %>
                        <%= recognition_badge("vafspotter") if vaf_spotter_ids.include?(csv_ids[i].to_i) %>
                      </td>
                      <% row.each do |element| %>
                        <td data-sort="<%= element %>">
                          <%= element %>
                        </td>
                      <% end %>
                    </tr>
                  <% end %>
                </tbody>
              </table>
            </div>
            <% else %>
              <div class="alert alert-info">
                <span class="fa fa-info-circle"></span>
                No results are currently available for this challenge.
              </div>
            <% end %>
        </div>
      </div>
    </div>
  </div>
</div>
